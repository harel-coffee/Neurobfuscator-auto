import torch
import time
import torch.nn.functional as F
import gym
import os
import sys
import numpy as np
import pandas as pd
import argparse
import math
import json
from datetime import datetime
from torch_relay_obfuscate import Obfuscator
from torch_utils import setup_logger
import logging
logging.getLogger('autotvm').setLevel(logging.FATAL)
sys.path.append('../seq_predictor')
from predict import predictor
from torch.jit import TracerWarning
import warnings
warnings.filterwarnings("ignore", category=TracerWarning)
np.random.seed(1234)

def random_act_dict_gen(env, range_list, fixed_shorter_fuse = True):
    act_dict = {}
    '''Randomly Generate Obfuscating operators'''
    '''widen_list: type: float, range: [1.0, inf), help: the factor to the output channel/dim of current layer'''
    '''decompo_list: type: int, range: [0, 4], help: 0: Do nothing, 1: branch the oc by 2, 2: branch the oc by 4, 3: branch the ic by 2, 4: branch the ic by 4'''
    '''dummy_list: type: int, range: [0, inf), help: adding zero vector (same shape as current layer's activation) by N times'''
    '''deepen_list: type: bin, help: add (or not) a deepen layer to the current layer'''
    '''skipcon_list: type: bin, help: add (or not) a skipconnection layer to the current layer'''
    '''kerneladd_list: type: int, range: [0, 1], help: padding zero to filter and input feature map, to fake a large filter size, 0: nothing, 1: padding 1 (filter size 3->5)'''

    '''prune_list: type int, range: [0, 1] for prune_bin_entry, [0, 3] for prune_4_entry'''


    '''widen_list follow 1 + 0.125 * randint[1,5) * bernouli (controlled by range_list[0])'''
    act_dict['widen_list'] = list(1 + 0.125 * (np.random.randint(low = 1, high = 5, size=(1, env.Obfuscator.get_full_length())) * np.random.binomial(size=(1, env.Obfuscator.get_full_length()), n=1, p = range_list[0])).flatten())

    '''decompo_list follow randint[0, 5)'''
    act_dict['decompo_list'] = list((np.random.randint(low = 0, high = 5, size=(1, env.Obfuscator.get_full_length())) * np.random.binomial(size=(1, env.Obfuscator.get_full_length()), n=1, p = range_list[1])).flatten())
    # act_dict['decompo_list'] = list(np.random.randint(5, size=(1, env.Obfuscator.get_full_length())).flatten())

    '''dummy_list follow randint[0, 5)  * bernouli (controlled by range_list[0])'''
    act_dict['dummy_list'] = list((np.random.randint(5, size=(1, env.Obfuscator.get_full_length())) * np.random.binomial(size=(1, env.Obfuscator.get_full_length()), n=1, p = range_list[2])).flatten())

    '''lists below follow bernouli (controlled by range_list[2], [3], [4])'''
    act_dict['deepen_list'] = list(np.random.binomial(size=(1, env.Obfuscator.get_full_length()), n=1, p = range_list[3]).flatten())
    act_dict['skipcon_list'] = list(np.random.binomial(size=(1, env.Obfuscator.get_full_length()), n=1, p = range_list[4]).flatten())
    act_dict['kerneladd_list'] = list(np.random.binomial(size=(1, env.Obfuscator.get_conv_length()), n=1, p = range_list[5]).flatten())

    '''prune_list prune_bin_entry follows bernouli (controlled by range_list[5]), prune_4_entry follows randint[0, 4)'''
    prune_bin_entry = [1, 2, 5, 6, 7, 8, 13]
    prune_4_entry = [0, 3, 4, 9, 10, 11, 12]
    prune_array = np.zeros((14,))
    prune_array[prune_bin_entry] = np.random.binomial(size=(1, len(prune_bin_entry)), n=1, p = range_list[6])
    prune_array[prune_4_entry] = np.random.randint(4, size=(1, len(prune_4_entry))) * np.random.binomial(size=(1, len(prune_4_entry)), n=1, p = range_list[6])
    act_dict['prune_list'] = list(prune_array.flatten())

    # env.prepare(act_dict)

    '''fuse_list follow randint[0, 10)  * bernouli (controlled by range_list[0])'''
    if fixed_shorter_fuse:
        fuse_list = list((10 * np.ones((1, 3 * env.Obfuscator.get_full_length())) - np.random.randint(10, size=(1, 3 * env.Obfuscator.get_full_length())) * np.random.binomial(size=(1, 3 * env.Obfuscator.get_full_length()), n=1, p = range_list[7])).flatten())
    else:
        fuse_list = list((10 * np.ones((1, env.Obfuscator.get_fuse_length())) - np.random.randint(10, size=(1, env.Obfuscator.get_fuse_length())) * np.random.binomial(size=(1, env.Obfuscator.get_fuse_length()), n=1, p = range_list[7])).flatten())
    act_dict['fuse_list'] = fuse_list

    return act_dict

def csv_to_time_overhead(csv_file):
    '''Sum up the Cycles in the DNN's profiling report (.csv)'''
    df = pd.read_csv(csv_file, skiprows=2)
    trace_df = df[df['Metric Name'] == "Cycles"]
    trace_df= trace_df.replace(',','', regex=True)
    trace_df['Metric Value'] = pd.to_numeric(trace_df['Metric Value'])

    cost = trace_df['Metric Value'].sum()
    return cost

# def apply_noise(dict, noise_vector, sigma):
def apply_noise(dict, sigma, forbid_List):
    '''Apply noise to obfuscating operators'''
    '''All noise are Gaussian noise, generated by the noise-vector'''
    widen_arr = np.asarray(dict['widen_list'])
    decompo_arr = np.asarray(dict['decompo_list'])
    dummy_arr = np.asarray(dict['dummy_list'])
    deepen_arr = np.asarray(dict['deepen_list'])
    skipcon_arr = np.asarray(dict['skipcon_list'])
    kerneladd_arr = np.asarray(dict['kerneladd_list'])
    prune_array = np.asarray(dict['prune_list'])
    fuse_arr = np.asarray(dict['fuse_list'])

    noise_list = [1/8, 1/2, 1, 1/4, 1/4, 1/16, 1/4, 1/2, 1]

    if 'widen_list' in forbid_List:
        noise_list[0] = 0
    if 'decompo_list' in forbid_List:
        noise_list[1] = 0
    if 'dummy_list' in forbid_List:
        noise_list[2] = 0
    if 'deepen_list' in forbid_List:
        noise_list[3] = 0
    if 'skipcon_list' in forbid_List:
        noise_list[4] = 0
    if 'kerneladd_list' in forbid_List:
        noise_list[5] = 0
    if 'prune_list' in forbid_List:
        noise_list[6] = 0
        noise_list[7] = 0
    if 'fuse_list' in forbid_List:
        noise_list[8] = 0

    noise = np.random.randn(1, widen_arr.shape[0])
    widen_arr = widen_arr + noise_list[0] * np.floor(1/4 * sigma * noise)

    noise = np.random.randn(1, decompo_arr.shape[0])
    decompo_arr = decompo_arr + noise_list[1] * sigma * noise

    noise = np.random.randn(1, dummy_arr.shape[0])
    dummy_arr = dummy_arr + noise_list[2] * sigma * noise



    noise = np.random.randn(1, deepen_arr.shape[0])
    deepen_arr = deepen_arr + noise_list[3] * sigma * noise

    noise = np.random.randn(1, skipcon_arr.shape[0])
    skipcon_arr = skipcon_arr + noise_list[4] * sigma * noise

    noise = np.random.randn(1, kerneladd_arr.shape[0])
    kerneladd_arr = kerneladd_arr + noise_list[5] * sigma * noise

    noise = np.random.randn(1, prune_array.shape[0])
    prune_bin_entry = [1, 2, 5, 6, 7, 8, 13]
    prune_4_entry = [0, 3, 4, 9, 10, 11, 12]
    prune_array[prune_bin_entry] = np.clip(np.floor(prune_array[prune_bin_entry] + noise_list[6] * sigma * noise[0][prune_bin_entry]), 0, 1)
    prune_array[prune_4_entry] = np.clip(np.floor(prune_array[prune_4_entry] + noise_list[7] * sigma * noise[0][prune_4_entry]), 0, 3)

    noise = np.random.randn(1, fuse_arr.shape[0])
    fuse_arr = fuse_arr + noise_list[8] * sigma * noise

    act_dict = {}
    act_dict['widen_list'] = list(np.clip(widen_arr, 1, 2).flatten().astype(float))
    act_dict['decompo_list'] = list(np.clip(np.floor(decompo_arr), 0, 4).flatten().astype(int))
    act_dict['dummy_list'] = list(np.clip(np.floor(dummy_arr), 0, 4).flatten().astype(int))
    act_dict['deepen_list'] = list(np.clip(np.floor(deepen_arr), 0, 1).flatten().astype(int))
    act_dict['skipcon_list'] = list(np.clip(np.floor(skipcon_arr), 0, 1).flatten().astype(int))
    act_dict['kerneladd_list'] = list(np.clip(np.floor(kerneladd_arr), 0, 1).flatten().astype(int))
    act_dict['prune_list'] = list(prune_array.flatten().astype(int))
    act_dict['fuse_list'] = list(np.clip(np.floor(fuse_arr), 0, 9).flatten().astype(int))
    return act_dict

def cal_pop_fitness(env, parent_list):
    fitness_list = []
    cycle_list = []
    LER_list = []
    for parent in parent_list:
        # env1.prepare(parent)
        fitness, cycle, _, avg_LER, _ = env1.step(parent)
        fitness_list.append(fitness)
        cycle_list.append(cycle)
        LER_list.append(avg_LER)
    return fitness_list, cycle_list, LER_list

def select_mating_pool(parent_list, fitness_list, n_mating):
    parents = []
    fitness_array = np.array(fitness_list)
    for i in range(n_mating):
        max_index = np.where(fitness_array == np.max(fitness_array))
        max_index = max_index[0][0]
        parents.append(parent_list[max_index])
        fitness_array[max_index] = -99
    return parents

def crossover(parents, offspring_size):
    offspring = []
    length = len(parents[0]["decompo_list"])
    conv_length = len(parents[0]["kerneladd_list"])
    cross_point = np.random.randint(length)
    for k in range(offspring_size):
        parent1_idx = k%len(parents)
        parent2_idx = (k+1)%len(parents)
        parent1_dict = parents[parent1_idx]
        parent2_dict = parents[parent2_idx]
        fuse_length = max(len(parent1_dict["fuse_list"]), len(parent2_dict["fuse_list"]))
        of_dict = {}
        of_dict["widen_list"] = parent1_dict["widen_list"][:cross_point]
        of_dict["widen_list"].extend(parent2_dict["widen_list"][cross_point:])
        of_dict["decompo_list"] = parent1_dict["decompo_list"][:cross_point]
        of_dict["decompo_list"].extend(parent2_dict["decompo_list"][cross_point:])

        of_dict["deepen_list"] = parent1_dict["deepen_list"][:cross_point]
        of_dict["deepen_list"].extend(parent2_dict["deepen_list"][cross_point:])
        of_dict["skipcon_list"] = parent1_dict["skipcon_list"][:cross_point]
        of_dict["skipcon_list"].extend(parent2_dict["skipcon_list"][cross_point:])
        of_dict["kerneladd_list"] = parent1_dict["kerneladd_list"][:int(conv_length/2)]
        of_dict["kerneladd_list"].extend(parent2_dict["kerneladd_list"][int(conv_length/2):])

        of_dict["prune_list"] = parent1_dict["prune_list"][:7]
        of_dict["prune_list"].extend(parent2_dict["prune_list"][7:])

        of_dict["dummy_list"] = parent1_dict["dummy_list"][:cross_point]
        of_dict["dummy_list"].extend(parent2_dict["dummy_list"][cross_point:])
        of_dict["fuse_list"] = parent1_dict["fuse_list"][:int(fuse_length/2)]
        of_dict["fuse_list"].extend(parent2_dict["fuse_list"][int(fuse_length/2):])
        offspring.append(of_dict)
    return offspring

def mutation(offspring_list, sigma, forbid_List):
    for i in range(len(offspring_list)):
        offspring_list[i] = apply_noise(offspring_list[i], sigma = sigma, forbid_List = forbid_List)
    return offspring_list

def ga_file_picker(dir_path, model_id, predict_type):
    file_dict = {}
    for filename in os.listdir(dir_path):
        if ("{}_genetic_algorithm_model{}".format(predict_type, model_id+1)) in filename:
            date_time = int(filename.split("_")[5].split(".log")[0])
            if filename not in file_dict:
                file_dict[filename] = date_time
    print(sorted(file_dict.keys()))
    if len(file_dict) >= 2:
        newest_file = sorted(file_dict.keys())[-2]
    else:
        return None
    return newest_file

def ga_extract_from_history(history, num_pop):
    parent_list = []
    pop_cnt = 0
    with open(history, "r") as in_file:
        buf = in_file.readlines()
    for line in buf:
        if "Final Action: " in line:
            pop_cnt += 1
            dict_string = line.split("Final Action: ")[1].replace("'", "\"").replace('\n', "")
            print(dict_string)
            pop_dict = json.loads(dict_string)
            parent_list.append(pop_dict)
        if pop_cnt >= num_pop:
            return parent_list

    return parent_list

class obf_env(gym.Env):
    def __init__(self, batch_size, input_features, nn_id = 4, normalize = "smart", model_name_list = ["deepsniffer_LSTM_both_autotvm_smart_64_cifar10"], restore_step = 149, reward_type = "divide_square_residue", autotvm_on = True, n_trial = 200, tuner = 'xgb', budget = 0.1):
        self.reward_type = reward_type
        self.model_id = nn_id
        self.batch_size=batch_size
        self.input_features=input_features
        restore_step = restore_step
        self.sample_file = "./env_file/lib_model_{}_obf_env.csv".format(self.model_id+1)
        if not os.path.isfile(self.sample_file):
            open(self.sample_file, 'w').close()
        self.label_file = "./model_file/model_{}.npy".format(self.model_id+1)
        assert os.path.isfile(self.label_file), "EnvironmentError: Label file must be provided to start the environment"

        self.Obfuscator = Obfuscator(self.model_id, self.batch_size, self.input_features, autotvm_on, n_trial, tuner)
        print("Number of predictors used to give score is: ", len(model_name_list))
        self.predictor_list = []
        for model_name in model_name_list:
            log_dir = "../seq_predictor/obfuscator/predictor/{}".format(model_name)
            num_hidden = int(model_name.split("_")[-2])
            if model_name.split("_")[1] == "full":
                predict_type = "full"
            elif model_name.split("_")[1] == "timeonly":
                predict_type = "time_only"
            elif "deepsniffer" in model_name.split("_")[1]:
                predict_type = "reduced"
            # print(model_name.split("_"), predict_type, num_hidden)
            self.predictor_list.append(predictor(log_dir, restore_step, self.label_file, self.sample_file, predict_type, normalize, num_hidden))

        self.done = False
        self.reward = 0.0
        self.clean_dict = self.Obfuscator.get_current_dict()
        self.clean_cycle = 0.0
        self.cost = 0.0
        self.budget = budget
    def step(self, action_dict):
        self.cost = self.take_action(action_dict)
        #Get current reward
        reward_0, avg_LER, predict, distance_list = self.get_reward()
        self.reward = reward_0
        return self.reward, self.cost, predict, avg_LER, distance_list

    def print_dict(self):
        return self.Obfuscator.print_dict_string()

    def take_action(self, action_dict):
        """ Converts the action space into an HFO action. """
        widen_list = action_dict['widen_list']
        decompo_list = action_dict['decompo_list']
        dummy_list = action_dict['dummy_list']
        deepen_list = action_dict['deepen_list']
        skipcon_list = action_dict['skipcon_list']
        kerneladd_list = action_dict['kerneladd_list']
        prune_list = action_dict['prune_list']
        fuse_list = action_dict['fuse_list']
        self.Obfuscator.apply_dd(widen_list, decompo_list, dummy_list, deepen_list, skipcon_list, kerneladd_list, prune_list)
        self.Obfuscator.apply_fuse(fuse_list)
        self.Obfuscator.trace_gen()
        try:
            cost = csv_to_time_overhead(self.sample_file)
        except:
            print("Error: Fail to run cost evaluation, trace might be incomplete")
            cost = math.inf
        return cost

    def get_reward(self):
        """ Reward is given for scoring a goal. """
        # try:
        min_dist = 9999
        total_dist = 0
        distance_list = []
        for predictor in self.predictor_list:
            distance, predict = predictor.get_reward()
            distance_list.append(distance)
            # print(distance)
            total_dist += distance
            if distance < min_dist:
                min_dist = distance
                best_predict = predict
        offset = (self.budget / 2.) ** 2
        if self.cost == self.clean_cycle or self.clean_cycle == 0:
            reward = 0.0
        else:
            if self.cost/self.clean_cycle - 1.0 - self.budget > 0:
                if self.reward_type == "divide_residue_offseted":
                    reward = total_dist/ len(self.predictor_list) * (1/ (np.abs(self.cost/self.clean_cycle - 1.0 - self.budget) + offset))
                elif self.reward_type == "divide_square_residue_offseted":
                    reward = total_dist/ len(self.predictor_list) * (1/ ((self.cost/self.clean_cycle - 1.0 - self.budget)**2 + offset))
            else:
                reward = total_dist/ len(self.predictor_list) *  (1/ offset)
        
        return reward, total_dist/ len(self.predictor_list), best_predict, distance_list
    def reset(self):
        """ Repeats NO-OP action until a new episode begins. """
        self.reward, self.cost, self.predict, avg_LER, distance_list= self.step(self.clean_dict)
        self.clean_cycle = self.cost
        self.clean_LER = avg_LER
        return self.reward, self.cost, self.predict, distance_list

if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--model_name_base', type=str, default='deepsniffer_LSTM_both_autotvm_smart')
    parser.add_argument('--model_name_afterfix', type=str, default='cifar10')
    parser.add_argument('--num_predictor_model', type=int, default=5)
    parser.add_argument('--run_option', type=str, default='random')
    parser.add_argument('--restore_step', type=int, default=149, help='Global step to restore from checkpoint.')
    parser.add_argument('--normalize', type=str, default="smart", help='Pick normalization for the training data, need to match with the predictor', choices=("sb", "smart"))
    parser.add_argument('--predict_type', type=str, default="reduced", help='Pick dataset you want to predict on', choices=("all", "reduced", "full", "time_only"))
    parser.add_argument('--nn_id', type=int, default=3, help='user\'s model id')
    parser.add_argument('--batch_size', type=int, default=1, help='batch_size')
    parser.add_argument('--input_features', type=int, default=3072, help='input_features')
    parser.add_argument('--n_trial', type=int, default=50, help='number of iteration for auto-scheduler')
    parser.add_argument('--n_generation', type=int, default=20, help='number of geenration for GA')
    parser.add_argument('--n_pop', type=int, default=16, help='number of population for GA')
    parser.add_argument('--autotvm_on', action='store_true', default=True, help='Use TVM auto-scheduler or not')
    parser.add_argument('--has_skip', action='store_true', default=False, help='Must use this flag if the model to obfuscate contains skip-connection, widen will be forbiddened if model has skip')
    parser.add_argument('--forbid_decompo', action='store_true', default=False, help='forbid decompose operator')
    parser.add_argument('--forbid_dummy', action='store_true', default=False, help='forbid dummy operator')
    parser.add_argument('--forbid_deepen', action='store_true', default=False, help='forbid deepen operator')
    parser.add_argument('--forbid_skipcon', action='store_true', default=False, help='forbid skipcon operator')
    parser.add_argument('--forbid_kerneladd', action='store_true', default=False, help='forbid kerneladd operator')
    parser.add_argument('--forbid_prune', action='store_true', default=False, help='forbid prune operator')
    parser.add_argument('--forbid_fuse', action='store_true', default=False, help='forbid fuse operator')
    parser.add_argument('--continue_from_newest', action='store_true', default=False, help='Use this flag to continue doing GA from newest GA history')
    parser.add_argument('--tuner', type=str, default="xgb", choices = ['xgb', 'xgb-rank', 'ga', 'random', 'gridsearch'], help='type of tuner for autoTVM')
    parser.add_argument('--reward_type', type=str, default="divide_square_residue", choices = ['divide_residue', 'divide_square_residue', 'divide_square_residue_offseted'], help='type of fitness score')
    parser.add_argument('--budget', type=float, default=0.1, help='Time budget to do the obfuscation')
    args = parser.parse_args()

    '''Set the type of searching'''
    run = args.run_option


    '''for debug'''
    # newest_history = ga_file_picker(dir_path = "./", model_id = args.nn_id)
    # parent_list = ga_extract_from_history(newest_history, num_pop = 8)
    # print(len(parent_list))

    '''Set the model_name_list'''
    num_neuron_list = [512, 256, 128, 96, 64]
    model_name_list = []
    for i in range(args.num_predictor_model):
        if args.predict_type == "full":
            model_name_list.append("logs_full_{}_{}_{}".format(args.model_name_base, num_neuron_list[i], args.model_name_afterfix))
        elif args.predict_type == "reduced":
            model_name_list.append("logs_{}_{}_{}".format(args.model_name_base, num_neuron_list[i], args.model_name_afterfix))
        elif args.predict_type == "time_only":
            model_name_list.append("logs_timeonly_{}_{}_{}".format(args.model_name_base, num_neuron_list[i], args.model_name_afterfix))
        elif args.predict_type == "all":
            model_name_list.append("logs_full_{}_{}_{}".format(args.model_name_base, num_neuron_list[i], args.model_name_afterfix))
            model_name_list.append("logs_{}_{}_{}".format(args.model_name_base, num_neuron_list[i], args.model_name_afterfix))
            model_name_list.append("logs_timeonly_{}_{}_{}".format(args.model_name_base, num_neuron_list[i], args.model_name_afterfix))
        elif args.predict_type == "customize":
            model_name_list.append("logs_full_{}_{}_{}".format(args.model_name_base, num_neuron_list[i], args.model_name_afterfix))
            model_name_list.append("logs_{}_{}_{}".format(args.model_name_base, num_neuron_list[i], args.model_name_afterfix))
    print("Model Name List is", model_name_list)


    '''Set the environment'''
    log_file = 'obfuscate_{}_{}_model{}_{}.log'.format(args.predict_type, run, args.nn_id+1, datetime.today().strftime('%m%d%H%M'))
    if not os.path.exists(log_file):
        open(log_file, 'a').close()

    logger = setup_logger('obfuscate_logger', log_file, level = logging.DEBUG, console_out = True)

    env1 = obf_env(args.batch_size, args.input_features, args.nn_id, args.normalize, model_name_list, args.restore_step, args.reward_type, args.autotvm_on, args.n_trial, args.tuner, args.budget)
    logger.debug("Initialize environment..\n")

    orig_reward, orig_cycle, orig_sequence, LER_list = env1.reset()
    logger.debug("\nOriginal Reward is {}".format(orig_reward))
    logger.debug("Reward Type is {}".format(env1.reward_type))
    logger.debug("Time Budget is {}".format(env1.budget))
    logger.debug("Predictor Type is {}".format(args.predict_type))
    logger.debug("Sequence is:" + orig_sequence)
    logger.debug("Clean LER is {}".format(env1.clean_LER))
    logger.debug("Clean Cycle is {:1.0f}\n".format(orig_cycle))
    logger.debug("LER list: {}".format(str(LER_list)))
    '''Set the record'''
    act_dict = {}
    best_reward = orig_reward
    best_prediction = orig_sequence
    best_cost = orig_cycle
    best_record = act_dict

    '''Start Run'''
    if run == "random": # random run, generate act_dict in pure random fashion

        '''Settings'''
        num_iter = 5
        has_skip = args.has_skip
        initialize_list = [0.2, 0.8, 0.4, 0.2, 0.2, 0.2, 0.4, 0.2]
        if_fixed_fuse = False
        if has_skip:
            initialize_list[0] = 0.0
        logger.debug("New Run: Random Strategy for %d iterations" %num_iter)
        logger.debug("Initialize with {}".format(str(initialize_list)))
        logger.debug("Fixed_Fuse is set to {}\n".format(if_fixed_fuse))
        for i in range(num_iter):
            logger.debug("=========Epoch %d=========\n"%i)
            act_dict = random_act_dict_gen(env1, initialize_list, fixed_shorter_fuse = if_fixed_fuse)
            reward, _, prediction, avg_LER, _ = env1.step(act_dict)
            logger.debug("\nCost is: {:1.0f}".format(env1.cost))
            logger.debug("\nAvg_LER is: {:1.0f}".format(avg_LER))
            logger.debug("Gets reward: {:1.8f}".format(reward))
            logger.debug("Current Action (Sparse): " + env1.print_dict())
            logger.debug("Current Action (Full):" + str(act_dict))
            if reward > best_reward:
                best_record = act_dict
                best_prediction = prediction
                best_reward = reward
                best_cost = env1.cost
    elif run == "onetime":
        logger.debug("New Run: One Time Cross test")
        logger.debug("=========Epoch 0=========\n")
        "Run with genetic algorithm in full mode, and copy the best action here, to do cross test [test on other two cases]"
        '''Paste the action dict below'''

        act_dict = {'widen_list': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'decompo_list': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0], 'dummy_list': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'deepen_list': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'skipcon_list': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'kerneladd_list': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'prune_list': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'fuse_list': [5, 4, 2, 9, 3, 0, 6, 9, 3, 0, 5, 0, 3, 4, 1, 2, 7, 0, 5, 4, 2, 5, 6, 2, 0, 7, 3, 4, 6, 5, 0, 5, 0, 4, 8, 5, 6, 4, 8, 8, 8, 5, 7, 8, 6, 7, 5, 8, 8, 3, 6, 8, 6, 8, 6, 5, 5]}

        reward_A, cost_A, prediction_A, avg_LER_A, distance_list = env1.step(act_dict)

        # logger.debug("Prediction for time_only: {:1.12f}".format(best_reward))
        logger.debug("Reward: {:1.12f}\n".format(reward_A))
        logger.debug("Prediction: " + prediction_A)
        logger.debug("Latency: {:1.0f}\n".format(cost_A))
        logger.debug("Average LER: {:1.6f}".format(avg_LER_A))
        logger.debug("LER list: {}".format(str(distance_list)))
        
        act_dict = {'widen_list': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'decompo_list': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 0, 1, 0, 1, 0], 'dummy_list': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'deepen_list': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'skipcon_list': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'kerneladd_list': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'prune_list': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'fuse_list': [3, 6, 0, 6, 7, 0, 7, 6, 4, 0, 6, 0, 4, 6, 0, 1, 3, 0, 4, 5, 9, 6, 5, 2, 1, 8, 2, 7, 9, 7, 8, 6, 5, 1, 8, 8, 2, 4, 5, 7, 3, 4, 5, 5, 2, 3, 6, 9, 3, 0, 7, 7, 4, 1, 3, 7, 6]}

        reward_A, cost_A, prediction_A, avg_LER_A, distance_list = env1.step(act_dict)

        logger.debug("Reward: {:1.12f}\n".format(reward_A))
        logger.debug("Prediction: " + prediction_A)
        logger.debug("Latency: {:1.0f}\n".format(cost_A))
        logger.debug("Average LER: {:1.6f}".format(avg_LER_A))
        logger.debug("LER list: {}".format(str(distance_list)))
        
        act_dict = {'widen_list': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'decompo_list': [3, 0, 0, 0, 3, 0, 0, 0, 0, 1, 0, 3, 0, 4, 0, 0, 1, 0, 1], 'dummy_list': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'deepen_list': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'skipcon_list': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'kerneladd_list': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'prune_list': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'fuse_list': [9, 8, 8, 7, 4, 9, 9, 6, 9, 8, 8, 9, 7, 3, 6, 8, 8, 3, 7, 9, 8, 9, 8, 9, 9, 6, 6, 6, 8, 6, 7, 7, 6, 9, 5, 9, 9, 9, 4, 9, 9, 7, 5, 6, 7, 5, 4, 3, 4, 0, 7, 7, 7, 2, 9, 5, 8]}
        
        reward_A, cost_A, prediction_A, avg_LER_A, distance_list = env1.step(act_dict)

        logger.debug("Reward: {:1.12f}\n".format(reward_A))
        logger.debug("Prediction: " + prediction_A)
        logger.debug("Latency: {:1.0f}\n".format(cost_A))
        logger.debug("Average LER: {:1.6f}".format(avg_LER_A))
        logger.debug("LER list: {}".format(str(distance_list)))
        
        act_dict = {'widen_list': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'decompo_list': [2, 0, 0, 0, 0, 4, 0, 0, 4, 3, 0, 0, 0, 4, 0, 0, 0, 0, 0], 'dummy_list': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'deepen_list': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'skipcon_list': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'kerneladd_list': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'prune_list': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'fuse_list': [6, 6, 2, 3, 4, 8, 7, 7, 2, 8, 4, 0, 6, 6, 0, 2, 2, 7, 6, 5, 8, 7, 2, 5, 4, 6, 7, 7, 7, 9, 6, 7, 5, 4, 8, 6, 7, 5, 9, 7, 8, 5, 9, 6, 3, 4, 6, 7, 6, 9, 3, 8, 1, 0, 1, 8, 8]}

        reward_A, cost_A, prediction_A, avg_LER_A, distance_list = env1.step(act_dict)

        logger.debug("Reward: {:1.12f}\n".format(reward_A))
        logger.debug("Prediction: " + prediction_A)
        logger.debug("Latency: {:1.0f}\n".format(cost_A))
        logger.debug("Average LER: {:1.6f}".format(avg_LER_A))
        logger.debug("LER list: {}".format(str(distance_list)))
        

        act_dict = {'widen_list': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'decompo_list': [3, 0, 4, 0, 1, 4, 0, 0, 4, 1, 0, 0, 0, 4, 4, 0, 0, 0, 0], 'dummy_list': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'deepen_list': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], 'skipcon_list': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], 'kerneladd_list': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'prune_list': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'fuse_list': [2, 9, 9, 7, 8, 5, 4, 8, 9, 1, 2, 8, 6, 7, 9, 9, 8, 7, 6, 9, 9, 6, 9, 9, 9, 9, 9, 5, 9, 7, 8, 9, 9, 7, 7, 4, 9, 8, 5, 9, 8, 9, 8, 8, 9, 9, 9, 8, 0, 2, 6, 9, 9, 4, 9, 9, 9]}
        
        reward_A, cost_A, prediction_A, avg_LER_A, distance_list = env1.step(act_dict)

        logger.debug("Reward: {:1.12f}\n".format(reward_A))
        logger.debug("Prediction: " + prediction_A)
        logger.debug("Latency: {:1.0f}\n".format(cost_A))
        logger.debug("Average LER: {:1.6f}".format(avg_LER_A))
        logger.debug("LER list: {}".format(str(distance_list)))
        
        exit()
        
    elif run == "genetic_algorithm":

        '''Settings'''
        npop = args.n_pop
        n_generation = args.n_generation
        n_mating = int(npop/2)
        initialize_list = [0.1, 0.4, 0.2, 0.1, 0.1, 0.1, 0.2, 0.1]
        if_fixed_fuse = True
        mutation_sigma = 8.0
        mutation_forbid_list = []
        continue_from_newest = args.continue_from_newest

        '''Apply Obfuscator Forbidden list'''
        if args.has_skip:
            initialize_list[0] = 0.0
            mutation_forbid_list.append('widen_list')
        if args.forbid_decompo:
            initialize_list[1] = 0.0
            mutation_forbid_list.append('decompo_list')
        if args.forbid_dummy:
            initialize_list[2] = 0.0
            mutation_forbid_list.append('dummy_list')
        if args.forbid_deepen:
            initialize_list[3] = 0.0
            mutation_forbid_list.append('deepen_list')
        if args.forbid_skipcon:
            initialize_list[4] = 0.0
            mutation_forbid_list.append('skipcon_list')
        if args.forbid_kerneladd:
            initialize_list[5] = 0.0
            mutation_forbid_list.append('kerneladd_list')
        if args.forbid_prune:
            initialize_list[6] = 0.0
            mutation_forbid_list.append('prune_list')
        if args.forbid_fuse:
            initialize_list[7] = 0.0
            mutation_forbid_list.append('fuse_list')

        parent_list = []
        fitness_list = []
        fitness = np.zeros(npop)
        logger.debug("New Run: Genetic Algorithm of population {}, generation {} and mating {}".format(npop, n_generation, n_mating))

        newest_history = ga_file_picker(dir_path = "./", model_id = args.nn_id, predict_type = args.predict_type)
        # newest_history = 
        if newest_history is None:
            continue_from_newest = False

        if continue_from_newest:
            logger.debug("Continue with old run {}".format(newest_history))
            mutation_sigma = 8.0
            logger.debug("Sigma for Mutation is set to {}\n".format(mutation_sigma))
        else:
            logger.debug("Initialize with {}".format(str(initialize_list)))
        logger.debug("Fixed_Fuse is set to {}\n".format(if_fixed_fuse))
        logger.debug("Forbid_Widen is set to {}".format(args.has_skip))
        logger.debug("Forbid_Decomposition is set to {}".format(args.forbid_decompo))
        logger.debug("Forbid_Dummy is set to {}".format(args.forbid_dummy))
        logger.debug("Forbid_Deepen is set to {}".format(args.forbid_deepen))
        logger.debug("Forbid_SkipConnection is set to {}".format(args.forbid_skipcon))
        logger.debug("Forbid_KernelAdd is set to {}".format(args.forbid_kerneladd))
        logger.debug("Forbid_Prune is set to {}".format(args.forbid_prune))
        logger.debug("Forbid_Fuse is set to {}\n".format(args.forbid_fuse))
        logger.debug("Initial Sigma for Mutation is set to {}\n".format(mutation_sigma))
        if continue_from_newest:
            parent_list = ga_extract_from_history(newest_history, 16)
            if npop >= len(parent_list):
                for j in range(npop - len(parent_list)):
                    w = random_act_dict_gen(env1, range_list = initialize_list, fixed_shorter_fuse = if_fixed_fuse)
                    parent_list.append(w)
            else:
                parent_list = parent_list[:npop]
        else:
            for j in range(npop):
                w = random_act_dict_gen(env1, range_list = initialize_list, fixed_shorter_fuse = if_fixed_fuse)
                parent_list.append(w)
        for generation in range(n_generation):
            logger.debug("\nGeneration: " + str(generation))
            if generation % 4 == 0 and generation != 0:
                mutation_sigma = mutation_sigma/2
                logger.debug("Mutation Sigma decay to: " + str(mutation_sigma))
            fitness_list, cycle_list, LER_list = cal_pop_fitness(env1, parent_list)
            fitness_array = np.asarray(fitness_list)
            max_index = np.where(fitness_array == np.max(fitness_array))
            max_index = max_index[0][0]
            best_cycle = cycle_list[max_index]
            best_score = fitness_list[max_index]
            best_LER = LER_list[max_index]
            logger.debug("\nBest Fitness Score so far is: " + str(best_score) + ", its Latency is: " + str(best_cycle) + ", its avg_LER is: " + str(best_LER))

            parent_string = ""
            for i in range(npop):
                parent_string += ("\n[{}] Fitness Score: ".format(i) + str(fitness_list[i]) + "; avgLER: {}; Cycle: {}".format(LER_list[i], cycle_list[i]) + "; Action: " + str(parent_list[i]) + "\n")
            logger.debug(parent_string)
            parents = select_mating_pool(parent_list, fitness_list, n_mating)
            offspring_crossover = crossover(parents, npop - n_mating)
            offspring_mutation = mutation(offspring_crossover, mutation_sigma, mutation_forbid_list)
            parent_list[:len(parents)] = parents
            parent_list[len(parents):] = offspring_mutation



        fitness_list, _, _ = cal_pop_fitness(env1, parent_list)
        parent_string = ""
        for i in range(npop):
            parent_string += ("\n[{}] Final Fitness Score: ".format(i) + str(fitness_list[i]) + "; Final Action: " + str(parent_list[i]) + "\n")
        logger.debug(parent_string)

        fitness_array = np.asarray(fitness_list)
        max_index = np.where(fitness_array == np.max(fitness_array))
        max_index = max_index[0][0]

        best_record = parent_list[max_index]
        # env1.prepare(best_record)
        best_reward, best_cost, best_prediction, avg_LER, distance_list = env1.step(best_record)
        logger.debug("LER list: {}".format(str(distance_list)))
    else:
        exit()
    logger.debug("Best Reward: {:1.12f}".format(best_reward))
    logger.debug("Best Prediction:" + best_prediction)
    logger.debug("Best Latency: {:1.0f}".format(best_cost))
    logger.debug("Best Average LER: {:1.6f}".format(avg_LER))
    logger.debug("Best Action (Sparse): " + env1.print_dict())
    logger.debug("Best Action (Full):" + str(best_record))
